
# ğŸ“˜ Student Performance Prediction using Machine Learning

## ğŸ“Œ Project Overview

This project focuses on **analyzing student behavioral and academic data** to predict their **performance level** (`Low`, `Medium`, `High`).
Using **Exploratory Data Analysis (EDA)** and multiple **classification algorithms**, we identify the most influential factors affecting student outcomes and build robust predictive models.

Dataset used: **xAPI-Edu-Data.csv**

---

## ğŸ¯ Objectives

* Perform **data cleaning & feature selection**
* Conduct **EDA** to understand student behavior patterns
* Build and compare **multiple ML classification models**
* Address **overfitting** using hyperparameter tuning
* Identify **key factors influencing student performance**

---

## ğŸ—‚ï¸ Dataset Description

The dataset contains:

* **Demographics:** Gender, Nationality, Relation
* **Academic attributes:** StageID, GradeID, Topic
* **Behavioral metrics:** RaisedHands, VisitedResources, AnnouncementsView, Discussion
* **Target Variable:**

  * `Class` â†’ Student performance

    * `L` = Low
    * `M` = Medium
    * `H` = High

---

## ğŸ§¹ Data Preprocessing Steps

### 1ï¸âƒ£ Initial Exploration

* Checked:

  * Data types
  * Null values (No missing data found)
  * Unique values for each column
* Generated descriptive statistics

---

### 2ï¸âƒ£ Feature Engineering & Selection

* Added a dummy `Institute` column to demonstrate **singularity handling**
* Dropped features based on:

  * **Singularity:** `Institute`
  * **Domain knowledge:** `SectionID`, `Semester`
  * **High cardinality:** `Topic`

âœ”ï¸ Result: Reduced dimensionality and improved model generalization

---

### 3ï¸âƒ£ Encoding

* Applied **Label Encoding** to categorical variables
* Used **manual ordinal encoding** for target variable:

```text
L â†’ 0 | M â†’ 1 | H â†’ 2
```

---

### 4ï¸âƒ£ Feature Scaling

* Applied **StandardScaler** to normalize numerical features
* Ensures fair contribution of all variables to ML models

---

## ğŸ“Š Exploratory Data Analysis (EDA)

### ğŸ”¹ Numerical Analysis

* Histograms revealed:

  * High engagement in **VisitedResources**
  * Lower participation in **AnnouncementsView** and **Discussion**
  * Moderate activity in **RaisedHands**

### ğŸ”¹ Pair Plots

* High and Low performers are **clearly separable**
* Medium performers are **scattered**, overlapping both extremes

### ğŸ”¹ Categorical Insights

* **Gender:**

  * Male students are more in number
  * Female students show **higher proportion of high performers**
* **Absenteeism:**

  * Students absent **< 7 days** are significantly more successful
* **Parental involvement & satisfaction** impact outcomes noticeably

---

## ğŸ¤– Machine Learning Models Used

### 1ï¸âƒ£ Logistic Regression

* Baseline multi-class classifier
* Good interpretability
* Moderate accuracy

ğŸ“Œ Observations:

* Works well for linear decision boundaries
* Limited performance for complex patterns

---

### 2ï¸âƒ£ Decision Tree Classifier

* Captures non-linear relationships
* Initial model showed **overfitting**

  * High training accuracy
  * Lower test accuracy

#### ğŸ”§ Overfitting Control:

Applied:

* `max_depth`
* `min_samples_leaf`

âœ”ï¸ Result:

* Balanced training & test performance
* Improved generalization

---

### 3ï¸âƒ£ Random Forest Classifier

* Ensemble of decision trees
* Reduced variance and overfitting
* Higher accuracy than single tree

---

### 4ï¸âƒ£ Hyperparameter Tuning

Used **RandomizedSearchCV** to optimize:

* `n_estimators`
* `max_depth`
* `min_samples_leaf`

âœ”ï¸ Result:

* Best performing model
* Improved cross-validation score
* Strong generalization on unseen data

---

## ğŸ“ˆ Model Evaluation Metrics

* **Confusion Matrix**
* **Accuracy Score**
* **Precision, Recall, F1-Score**
* **Train vs Test Accuracy comparison**

Heatmaps were used for intuitive visualization of classification performance.

---

## ğŸ” Feature Importance Analysis

* Decision Tree & Random Forest identified:

  * `VisitedResources`
  * `RaisedHands`
  * `AnnouncementsView`
  * `Discussion`

as the **most influential features** in predicting performance.

---

## ğŸ§ª Final Optimized Model Performance

| Model                 | Test Accuracy |
| --------------------- | ------------- |
| Logistic Regression   | Moderate      |
| Decision Tree (Tuned) | High          |
| Random Forest (Tuned) | **Highest** âœ… |

---

## ğŸ Conclusion

* **Student engagement metrics** are stronger predictors than demographics
* Absenteeism is a **critical risk indicator**
* Ensemble models outperform individual classifiers
* Proper feature selection & tuning significantly improve accuracy

---

## ğŸš€ Future Enhancements

* Apply **XGBoost / LightGBM**
* Perform **SMOTE** for class imbalance
* Deploy model using **Flask / Streamlit**
* Add explainability using **SHAP values**

---

## ğŸ› ï¸ Tech Stack

* **Python**
* **Pandas, NumPy**
* **Matplotlib, Seaborn**
* **Scikit-Learn**

---


